| Topic | Description |
| --- | --- |
| Prompt Engineering | The process of iteratively refining and improving the input prompt to a large language model in order to achieve better results and have more control over the model's output. |
| Narrow NLP vs. Large Language Models | Narrow NLP models are trained on specific tasks such as text classification or sentiment analysis, while large language models are capable of performing a wide range of tasks under the same hood. |
| Advantages of Large Language Models | Large language models are versatile, have better generalization capabilities, and require less maintenance, especially when using a closed-source model. |
| Disadvantages of Large Language Models | The cost of using a large language model can be a downside, as well as the inability to use them offline, potential privacy concerns, and the difficulty in interpreting the model's output. |
| What is a Prompt? | A prompt is the input that a user provides to a large language model, which may include context, the desired length and format of the output, and the tone of the response. |
| What is Prompt Engineering? | The iterative process of refining and improving a prompt by evaluating the model's output, assessing whether the model understood the intended task, and adjusting the prompt accordingly. |
| Principles of Prompt Engineering | Some principles for effective prompt engineering include providing clear instructions, dividing the task into subtasks, using delimiters, asking the model for an explanation, using personas, providing examples, and controlling the model's output. |
| Clear Instructions | Providing clear and detailed instructions in a prompt can help the model understand the intended task and produce a more accurate and useful response. |
| Personas | Using personas in a prompt, or instructing the model to act as a certain character or persona, can help the model produce a more tailored and specific response. |
| Delimiters | Using delimiters in a prompt, such as triple quotations or XML tags, can help the model understand the structure of the input and produce a more accurate response. |
| Subtasks | Dividing a complex task into smaller subtasks in a prompt can help the model understand the intended task and produce a more accurate and useful response. |
| Examples | Providing examples in a prompt can help the model understand the intended task and produce a more accurate and useful response. |
| Output Control | Controlling the output of a large language model, such as specifying the desired length or format of the response, can help the user achieve the desired results. |